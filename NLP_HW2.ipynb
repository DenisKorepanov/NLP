{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihAY-70w9Uqn"
      },
      "source": [
        "Выполнил: Драгомирский Даглар Сарматович\n",
        "\n",
        "Группа: РИМ-220963"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eL1nLg-h9diF"
      },
      "source": [
        "### ДОМАШНЕЕ ЗАДАНИЕ №2\n",
        "В первой части проекта вы реализовывали классификацию при помощи эвристик и методов классического ML поверх векторизованных слов.\n",
        "\n",
        "В этой части нужно решить эту же задачу при помощи RNN.\n",
        "\n",
        "\n",
        "\n",
        "#### ЗАДАЧА\n",
        "Обучите несколько моделей рекуррентных нейронных сетей, например LSTM, GRU, Bidirectional-LSTM.\n",
        "Посчитайте значение метрики, которую вы предложили в части 1 и сравните результаты для разных RNN, эвристик и классического ML.\n",
        "\n",
        "\n",
        "#### РЕЗУЛЬТАТ:\n",
        "Jupyter-notebook с реализацией требуемых методов.\n",
        "\n",
        "Эту часть проекта мы будем оценивать по тем же критериям:\n",
        "\n",
        "Полнота выполненной работы;\n",
        "Общее качество кода и следование PEP-8;\n",
        "Итоговое значение метрики качества.\n",
        "\n",
        "\n",
        "#### ПОДСКАЗКИ:\n",
        "При работе с RNN можно экспериментировать не только с типом слоя, но и с гиперпараметрами.\n",
        "«Сравнить результаты» означает не просто посчитать метрику для разных методов, но и сделать вывод о том, что сработало лучше\n",
        "Не забудьте реализовать валидационную выборку и на ней отследить, что модель не переобучилась."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "b4o-ayE3uBE3"
      },
      "source": [
        "# ВАЖНАЯ ИНФА\n",
        "\n",
        "1. При решении д\\з с использованием  PyTorch столкнулся со значительными трудностями. В итоге было принято решение использовать tensorflow\n",
        "2. Используем уже обработанный датасет из 1-го д\\з"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8R_z4B597is"
      },
      "source": [
        "# Подключение необходимых библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkhPuH5D4HdY",
        "outputId": "f36eb25f-3474-493a-8d6d-7a0be4562158"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from typing import Literal\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tensorflow.keras import Sequential, layers\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3np-gDoBEoBT"
      },
      "source": [
        "## CONSTANTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "S-vkLD1PEevB"
      },
      "outputs": [],
      "source": [
        "\n",
        "#MODELS_FOLDER = os.path.join(DATA_FOLDER, \"models\")\n",
        "#Path(MODELS_FOLDER).mkdir(parents=True, exist_ok=True)\n",
        "PREPROCESSED_CSV = os.path.join(\"PREPROCESSED.csv\")\n",
        "EVAL_CSV = os.path.join(\"evaluate.csv\")\n",
        "EVAL_CSV_NEW = os.path.join(\"evaluate_new.csv\")\n",
        "EVAL_CSV_RATING = os.path.join(\"evaluate_rating.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBX8XuIR9Pp6"
      },
      "source": [
        "# Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "id": "Qr3_TBe3ICqZ",
        "outputId": "ce9a6e86-0c52-431c-ffe7-0fdbd560aa6f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>text_clean</th>\n",
              "      <th>text_stemmer</th>\n",
              "      <th>text_lemma</th>\n",
              "      <th>text_split</th>\n",
              "      <th>text_symbols_n</th>\n",
              "      <th>text_list_len</th>\n",
              "      <th>text_set_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...</td>\n",
              "      <td>3</td>\n",
              "      <td>menyrbie  philgahan  chrisitv</td>\n",
              "      <td>menyrbi philgahan chrisitv</td>\n",
              "      <td>menyrbie philgahan chrisitv</td>\n",
              "      <td>['menyrbie', 'philgahan', 'chrisitv']</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>advice Talk to your neighbours family to excha...</td>\n",
              "      <td>4</td>\n",
              "      <td>advice talk neighbours family exchange phone n...</td>\n",
              "      <td>advic talk neighbour famili exchang phone numb...</td>\n",
              "      <td>advice talk neighbour family exchange phone nu...</td>\n",
              "      <td>['advice', 'talk', 'neighbours', 'family', 'ex...</td>\n",
              "      <td>196</td>\n",
              "      <td>27</td>\n",
              "      <td>24</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Coronavirus Australia: Woolworths to give elde...</td>\n",
              "      <td>4</td>\n",
              "      <td>coronavirus australia  woolworths give elderly...</td>\n",
              "      <td>coronavirus australia woolworth give elder dis...</td>\n",
              "      <td>coronavirus australia woolworth give elderly d...</td>\n",
              "      <td>['coronavirus', 'australia', 'woolworths', 'gi...</td>\n",
              "      <td>101</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>My food stock is not the only one which is emp...</td>\n",
              "      <td>4</td>\n",
              "      <td>food stock one empty  please  nt panic  enough...</td>\n",
              "      <td>food stock one empti pleas nt panic enough foo...</td>\n",
              "      <td>food stock one empty please nt panic enough fo...</td>\n",
              "      <td>['food', 'stock', 'one', 'empty', 'please', 'n...</td>\n",
              "      <td>181</td>\n",
              "      <td>23</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Me, ready to go at supermarket during the #COV...</td>\n",
              "      <td>1</td>\n",
              "      <td>ready go supermarket  covid outbreak m parano...</td>\n",
              "      <td>readi go supermarket covid outbreak m paranoid...</td>\n",
              "      <td>ready go supermarket covid outbreak m paranoid...</td>\n",
              "      <td>['ready', 'go', 'supermarket', 'covid', 'outbr...</td>\n",
              "      <td>198</td>\n",
              "      <td>23</td>\n",
              "      <td>23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41135</th>\n",
              "      <td>Airline pilots offering to stock supermarket s...</td>\n",
              "      <td>3</td>\n",
              "      <td>airline pilots offering stock supermarket shel...</td>\n",
              "      <td>airlin pilot offer stock supermarket shelv nz ...</td>\n",
              "      <td>airline pilot offering stock supermarket shelf...</td>\n",
              "      <td>['airline', 'pilots', 'offering', 'stock', 'su...</td>\n",
              "      <td>69</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41136</th>\n",
              "      <td>Response to complaint not provided citing COVI...</td>\n",
              "      <td>1</td>\n",
              "      <td>response complaint provided citing covid relat...</td>\n",
              "      <td>respons complaint provid cite covid relat dela...</td>\n",
              "      <td>response complaint provided citing covid relat...</td>\n",
              "      <td>['response', 'complaint', 'provided', 'citing'...</td>\n",
              "      <td>109</td>\n",
              "      <td>16</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41137</th>\n",
              "      <td>You know itÂs getting tough when @KameronWild...</td>\n",
              "      <td>4</td>\n",
              "      <td>know getting tough  kameronwilds rationing toi...</td>\n",
              "      <td>know get tough kameronwild ration toilet paper...</td>\n",
              "      <td>know getting tough kameronwilds rationing toil...</td>\n",
              "      <td>['know', 'getting', 'tough', 'kameronwilds', '...</td>\n",
              "      <td>113</td>\n",
              "      <td>13</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41138</th>\n",
              "      <td>Is it wrong that the smell of hand sanitizer i...</td>\n",
              "      <td>3</td>\n",
              "      <td>wrong smell hand sanitizer starting turn   cor...</td>\n",
              "      <td>wrong smell hand sanit start turn coronavirus ...</td>\n",
              "      <td>wrong smell hand sanitizer starting turn coron...</td>\n",
              "      <td>['wrong', 'smell', 'hand', 'sanitizer', 'start...</td>\n",
              "      <td>74</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41139</th>\n",
              "      <td>@TartiiCat Well new/used Rift S are going for ...</td>\n",
              "      <td>2</td>\n",
              "      <td>tartiicat well newused rift going   amazon rn...</td>\n",
              "      <td>tartiicat well newus rift go amazon rn althoug...</td>\n",
              "      <td>tartiicat well newused rift going amazon rn al...</td>\n",
              "      <td>['tartiicat', 'well', 'newused', 'rift', 'goin...</td>\n",
              "      <td>169</td>\n",
              "      <td>26</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>41140 rows × 9 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    text  sentiment  \\\n",
              "0      @MeNyrbie @Phil_Gahan @Chrisitv https://t.co/i...          3   \n",
              "1      advice Talk to your neighbours family to excha...          4   \n",
              "2      Coronavirus Australia: Woolworths to give elde...          4   \n",
              "3      My food stock is not the only one which is emp...          4   \n",
              "4      Me, ready to go at supermarket during the #COV...          1   \n",
              "...                                                  ...        ...   \n",
              "41135  Airline pilots offering to stock supermarket s...          3   \n",
              "41136  Response to complaint not provided citing COVI...          1   \n",
              "41137  You know itÂs getting tough when @KameronWild...          4   \n",
              "41138  Is it wrong that the smell of hand sanitizer i...          3   \n",
              "41139  @TartiiCat Well new/used Rift S are going for ...          2   \n",
              "\n",
              "                                              text_clean  \\\n",
              "0                          menyrbie  philgahan  chrisitv   \n",
              "1      advice talk neighbours family exchange phone n...   \n",
              "2      coronavirus australia  woolworths give elderly...   \n",
              "3      food stock one empty  please  nt panic  enough...   \n",
              "4       ready go supermarket  covid outbreak m parano...   \n",
              "...                                                  ...   \n",
              "41135  airline pilots offering stock supermarket shel...   \n",
              "41136  response complaint provided citing covid relat...   \n",
              "41137  know getting tough  kameronwilds rationing toi...   \n",
              "41138  wrong smell hand sanitizer starting turn   cor...   \n",
              "41139   tartiicat well newused rift going   amazon rn...   \n",
              "\n",
              "                                            text_stemmer  \\\n",
              "0                             menyrbi philgahan chrisitv   \n",
              "1      advic talk neighbour famili exchang phone numb...   \n",
              "2      coronavirus australia woolworth give elder dis...   \n",
              "3      food stock one empti pleas nt panic enough foo...   \n",
              "4      readi go supermarket covid outbreak m paranoid...   \n",
              "...                                                  ...   \n",
              "41135  airlin pilot offer stock supermarket shelv nz ...   \n",
              "41136  respons complaint provid cite covid relat dela...   \n",
              "41137  know get tough kameronwild ration toilet paper...   \n",
              "41138  wrong smell hand sanit start turn coronavirus ...   \n",
              "41139  tartiicat well newus rift go amazon rn althoug...   \n",
              "\n",
              "                                              text_lemma  \\\n",
              "0                            menyrbie philgahan chrisitv   \n",
              "1      advice talk neighbour family exchange phone nu...   \n",
              "2      coronavirus australia woolworth give elderly d...   \n",
              "3      food stock one empty please nt panic enough fo...   \n",
              "4      ready go supermarket covid outbreak m paranoid...   \n",
              "...                                                  ...   \n",
              "41135  airline pilot offering stock supermarket shelf...   \n",
              "41136  response complaint provided citing covid relat...   \n",
              "41137  know getting tough kameronwilds rationing toil...   \n",
              "41138  wrong smell hand sanitizer starting turn coron...   \n",
              "41139  tartiicat well newused rift going amazon rn al...   \n",
              "\n",
              "                                              text_split  text_symbols_n  \\\n",
              "0                  ['menyrbie', 'philgahan', 'chrisitv']              30   \n",
              "1      ['advice', 'talk', 'neighbours', 'family', 'ex...             196   \n",
              "2      ['coronavirus', 'australia', 'woolworths', 'gi...             101   \n",
              "3      ['food', 'stock', 'one', 'empty', 'please', 'n...             181   \n",
              "4      ['ready', 'go', 'supermarket', 'covid', 'outbr...             198   \n",
              "...                                                  ...             ...   \n",
              "41135  ['airline', 'pilots', 'offering', 'stock', 'su...              69   \n",
              "41136  ['response', 'complaint', 'provided', 'citing'...             109   \n",
              "41137  ['know', 'getting', 'tough', 'kameronwilds', '...             113   \n",
              "41138  ['wrong', 'smell', 'hand', 'sanitizer', 'start...              74   \n",
              "41139  ['tartiicat', 'well', 'newused', 'rift', 'goin...             169   \n",
              "\n",
              "       text_list_len  text_set_len  \n",
              "0                  3             3  \n",
              "1                 27            24  \n",
              "2                 12            12  \n",
              "3                 23            20  \n",
              "4                 23            23  \n",
              "...              ...           ...  \n",
              "41135              9             9  \n",
              "41136             16            16  \n",
              "41137             13            13  \n",
              "41138              9             8  \n",
              "41139             26            26  \n",
              "\n",
              "[41140 rows x 9 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Используем уже обработанный датасет из 1-го д\\з:\n",
        "preprocessed_df = pd.read_csv(PREPROCESSED_CSV)\n",
        "preprocessed_df = preprocessed_df.dropna().reset_index(drop=True)\n",
        "preprocessed_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "hBLGcpBw_G86",
        "outputId": "05e86569-eda9-4737-be4b-a7d7209eb180"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>random</td>\n",
              "      <td>0.192929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>most_popular</td>\n",
              "      <td>0.279917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unique_words</td>\n",
              "      <td>0.301664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>multinomial_naive_bayes</td>\n",
              "      <td>0.444296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>random_forest_classifier</td>\n",
              "      <td>0.527153</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     method  accuracy\n",
              "0                    random  0.192929\n",
              "1              most_popular  0.279917\n",
              "2              unique_words  0.301664\n",
              "3   multinomial_naive_bayes  0.444296\n",
              "4  random_forest_classifier  0.527153"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Так же используем таблицу с оценками способов предсказания:\n",
        "eval_df = pd.read_csv(EVAL_CSV)\n",
        "eval_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CkUnwuCBBhG"
      },
      "source": [
        "# Подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JDwkE_yuBE9"
      },
      "source": [
        "Масштабируем оценки [1; 5] (где 1-негативно, 5-позитивно) -> в диапазон [0; 4]:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "qfF7XUTVPyg6"
      },
      "outputs": [],
      "source": [
        "preprocessed_df[\"sentiment\"] = preprocessed_df[\"sentiment\"].apply(lambda x: x - 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S7WFBpzGuBE-"
      },
      "source": [
        "Разделим на:\n",
        "- предикторы\n",
        "- target (собственно оценку текста):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "qFTn2cl9MME8"
      },
      "outputs": [],
      "source": [
        "X = preprocessed_df[\"text_clean\"]\n",
        "y = preprocessed_df[\"sentiment\"].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCGSqtDDMNbo",
        "outputId": "debb0323-80ca-4bfa-d5fc-bce38f81479e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size = 55648\n",
            "X.shape = (41140, 50)\n"
          ]
        }
      ],
      "source": [
        "MAX_LEN = 50\n",
        "\n",
        "# Токенизация текста\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(X)\n",
        "X = tokenizer.texts_to_sequences(X)\n",
        "\n",
        "# паддинг\n",
        "X = pad_sequences(X, padding='post', maxlen=MAX_LEN)\n",
        "MAX_VOCAB_SIZE = len(tokenizer.word_index)\n",
        "print(f\"Vocabulary size = {MAX_VOCAB_SIZE}\")\n",
        "print(f\"X.shape = {X.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DWpf7FyuBE_"
      },
      "source": [
        "Токенизированный текст -> train + test:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qVK1J7XIt-p",
        "outputId": "e4001df0-e290-4197-c572-a8ae47ce4af4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([  216,   881,   802,     2,  1470, 23569,  2571,   571, 11090,\n",
              "       23570,   789,   116,    26,     7,    54,   171,   175,  2103,\n",
              "         114,  8857,  7468,   719,   818,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    stratify=y,\n",
        "    test_size=0.1,\n",
        "    random_state=42,\n",
        ")\n",
        "X_train[4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "OBlQvUjTuBFA"
      },
      "outputs": [],
      "source": [
        "# Ключевые константы + гиперпараметры:\n",
        "EMBEDDING_DIM = 16\n",
        "HIDDEN_DIM = 256\n",
        "OUTPUT_SIZE = 5\n",
        "VOCAB_SIZE = MAX_VOCAB_SIZE + 1\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 3\n",
        "DROPOUT = 0.3\n",
        "VALIDATION_SPLIT = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "I-ogea_puBFA"
      },
      "outputs": [],
      "source": [
        "# Зададим класс MyNlp, в рамках которого будем задавать одну из нейросеток (GRU, LSTM, BDLSTM) -> активацию в главном слое -> обучение + тестирование модели на наших test/train данных:\n",
        "class MyNlp:\n",
        "    def __init__(\n",
        "        self,\n",
        "        model_type: Literal[\"GRU\", \"LSTM\", \"BDLSTM\"],\n",
        "        activation: str,\n",
        "        epoch: int = NUM_EPOCHS,\n",
        "        hidden_dim: int = HIDDEN_DIM,\n",
        "        vocab_size: int = VOCAB_SIZE,\n",
        "        embedding_dim: int = EMBEDDING_DIM,\n",
        "        input_length: int = MAX_LEN,\n",
        "        output_size: int = OUTPUT_SIZE,\n",
        "        batch_size: int = BATCH_SIZE,\n",
        "        dropout: float = DROPOUT,\n",
        "        validation_split: float = VALIDATION_SPLIT,\n",
        "    ) -> None:\n",
        "        self.model_name = f\"{model_type}_{activation}\"\n",
        "        if model_type == \"GRU\":\n",
        "            self.main_layer = layers.GRU(\n",
        "                hidden_dim,\n",
        "                return_sequences=True,\n",
        "            )\n",
        "        elif model_type == \"LSTM\":\n",
        "            self.main_layer = layers.LSTM(\n",
        "                hidden_dim,\n",
        "                return_sequences=True,\n",
        "            )\n",
        "        elif model_type == \"BDLSTM\":\n",
        "            self.main_layer = layers.Bidirectional(\n",
        "                layers.LSTM(\n",
        "                    hidden_dim,\n",
        "                    return_sequences=True,\n",
        "                )\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError('`model_type` should be one of \"GRU\", \"LSTM\", \"BDLSTM\"')\n",
        "        self.model = Sequential(\n",
        "            [\n",
        "                layers.Embedding(\n",
        "                    vocab_size,\n",
        "                    embedding_dim,\n",
        "                    input_length=input_length,\n",
        "                ),\n",
        "                self.main_layer,  # Main nlp layer depending on model type\n",
        "                layers.GlobalMaxPool1D(),\n",
        "                layers.Dropout(dropout),\n",
        "                layers.Dense(\n",
        "                    64,\n",
        "                    activation=activation,\n",
        "                ),\n",
        "                layers.Dropout(dropout),\n",
        "                layers.Dense(output_size),\n",
        "            ],\n",
        "            name=self.model_name,\n",
        "        )\n",
        "        self.optimizer = Adam()\n",
        "        self.epoch = epoch\n",
        "        self.validation_split = validation_split\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def _print_line(self, item: str = \"_\") -> None:\n",
        "        print(item * 65)\n",
        "\n",
        "    def compile(self) -> None:\n",
        "        self.model.compile(\n",
        "            loss=SparseCategoricalCrossentropy(from_logits=True),\n",
        "            optimizer=self.optimizer,\n",
        "            metrics=[\"accuracy\"],\n",
        "        )\n",
        "        self.model.summary()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "    def train(self, X, y) -> None:\n",
        "        print(f\"Start training model `{self.model_name}`:\")\n",
        "        self._print_line()\n",
        "        self.history = self.model.fit(\n",
        "            X,\n",
        "            y,\n",
        "            epochs=self.epoch,\n",
        "            validation_split=self.validation_split,\n",
        "            batch_size=self.batch_size,\n",
        "        )\n",
        "        self._print_line()\n",
        "        print(\"\\n\\n\")\n",
        "\n",
        "    def test(self, X, y) -> None:\n",
        "        print(f\"Start testing model `{self.model_name}`:\")\n",
        "        self._print_line()\n",
        "        y_predicted = np.argmax(\n",
        "            self.model.predict(X),\n",
        "            axis=1,\n",
        "        )\n",
        "        self.accuracy = accuracy_score(y_predicted, y)\n",
        "        print(f\"Test Accuracy: {round(self.accuracy, 6)}\")\n",
        "        self._print_line(\"**\")\n",
        "        print(\"\\n\\n\\n\")\n",
        "\n",
        "    def add_info_to_df(self, df) -> None:\n",
        "        df.loc[len(df)] = [\n",
        "            self.model_name,\n",
        "            self.accuracy,\n",
        "        ]\n",
        "\n",
        "    def save_model(self) -> None:\n",
        "        self.model.save(os.path.join(f\"{self.model_name}.keras\"))\n",
        "\n",
        "    def train_test_pipeline(\n",
        "        self,\n",
        "        X_train,\n",
        "        y_train,\n",
        "        X_test,\n",
        "        y_test,\n",
        "        df,\n",
        "    ) -> None:\n",
        "        self.compile()\n",
        "        self.train(X_train, y_train)\n",
        "        self.test(X_test, y_test)\n",
        "        self.add_info_to_df(df)\n",
        "        self.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMhnZ3VNhntz"
      },
      "source": [
        "Обучаем 3 нейросети -> для каждой 3 типа активации (elu, relu, leaky_relu):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9barMcHMWWb5",
        "outputId": "1ce0c898-ee0e-4e4b-9f14-eb9dac01f130"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"GRU_elu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " gru_1 (GRU)                 (None, 50, 256)           210432    \n",
            "                                                                 \n",
            " global_max_pooling1d_1 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,117,589\n",
            "Trainable params: 1,117,589\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `GRU_elu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 88s 41ms/step - loss: 1.0829 - accuracy: 0.5584 - val_loss: 0.7920 - val_accuracy: 0.7081\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 84s 40ms/step - loss: 0.6734 - accuracy: 0.7629 - val_loss: 0.7458 - val_accuracy: 0.7221\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 82s 39ms/step - loss: 0.4873 - accuracy: 0.8382 - val_loss: 0.7832 - val_accuracy: 0.7313\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `GRU_elu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 2s 15ms/step\n",
            "Test Accuracy: 0.721682\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"GRU_relu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " gru_2 (GRU)                 (None, 50, 256)           210432    \n",
            "                                                                 \n",
            " global_max_pooling1d_2 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,117,589\n",
            "Trainable params: 1,117,589\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `GRU_relu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 89s 42ms/step - loss: 1.0977 - accuracy: 0.5470 - val_loss: 0.7958 - val_accuracy: 0.7075\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 82s 39ms/step - loss: 0.6662 - accuracy: 0.7628 - val_loss: 0.7198 - val_accuracy: 0.7478\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 83s 40ms/step - loss: 0.4861 - accuracy: 0.8363 - val_loss: 0.7654 - val_accuracy: 0.7229\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `GRU_relu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 2s 16ms/step\n",
            "Test Accuracy: 0.718036\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"GRU_leaky_relu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_3 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " gru_3 (GRU)                 (None, 50, 256)           210432    \n",
            "                                                                 \n",
            " global_max_pooling1d_3 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,117,589\n",
            "Trainable params: 1,117,589\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `GRU_leaky_relu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 88s 41ms/step - loss: 1.0874 - accuracy: 0.5540 - val_loss: 0.7736 - val_accuracy: 0.7210\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 84s 40ms/step - loss: 0.6635 - accuracy: 0.7603 - val_loss: 0.7100 - val_accuracy: 0.7451\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 82s 39ms/step - loss: 0.4742 - accuracy: 0.8360 - val_loss: 0.7390 - val_accuracy: 0.7362\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `GRU_leaky_relu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 2s 15ms/step\n",
            "Test Accuracy: 0.722654\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"LSTM_elu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_4 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 50, 256)           279552    \n",
            "                                                                 \n",
            " global_max_pooling1d_4 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,186,709\n",
            "Trainable params: 1,186,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `LSTM_elu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 128s 61ms/step - loss: 1.1109 - accuracy: 0.5418 - val_loss: 0.7974 - val_accuracy: 0.7097\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 123s 59ms/step - loss: 0.6922 - accuracy: 0.7516 - val_loss: 0.7349 - val_accuracy: 0.7372\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 123s 59ms/step - loss: 0.5223 - accuracy: 0.8210 - val_loss: 0.7834 - val_accuracy: 0.7281\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `LSTM_elu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 5s 35ms/step\n",
            "Test Accuracy: 0.721682\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"LSTM_relu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 50, 256)           279552    \n",
            "                                                                 \n",
            " global_max_pooling1d_5 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,186,709\n",
            "Trainable params: 1,186,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `LSTM_relu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 129s 61ms/step - loss: 1.1625 - accuracy: 0.5149 - val_loss: 0.8371 - val_accuracy: 0.6886\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 126s 61ms/step - loss: 0.7202 - accuracy: 0.7408 - val_loss: 0.7811 - val_accuracy: 0.7100\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 128s 61ms/step - loss: 0.5325 - accuracy: 0.8168 - val_loss: 0.7852 - val_accuracy: 0.7254\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `LSTM_relu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 5s 36ms/step\n",
            "Test Accuracy: 0.731891\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"LSTM_leaky_relu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_6 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " lstm_2 (LSTM)               (None, 50, 256)           279552    \n",
            "                                                                 \n",
            " global_max_pooling1d_6 (Glo  (None, 256)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 256)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                16448     \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,186,709\n",
            "Trainable params: 1,186,709\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `LSTM_leaky_relu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 128s 61ms/step - loss: 1.1418 - accuracy: 0.5262 - val_loss: 0.8113 - val_accuracy: 0.6967\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 126s 61ms/step - loss: 0.6917 - accuracy: 0.7506 - val_loss: 0.7272 - val_accuracy: 0.7397\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 126s 61ms/step - loss: 0.5090 - accuracy: 0.8266 - val_loss: 0.7478 - val_accuracy: 0.7297\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `LSTM_leaky_relu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 5s 35ms/step\n",
            "Test Accuracy: 0.716334\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"BDLSTM_elu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_7 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 50, 512)          559104    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " global_max_pooling1d_7 (Glo  (None, 512)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,482,645\n",
            "Trainable params: 1,482,645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `BDLSTM_elu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 206s 97ms/step - loss: 1.0547 - accuracy: 0.5752 - val_loss: 0.8075 - val_accuracy: 0.7110\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 200s 96ms/step - loss: 0.6590 - accuracy: 0.7675 - val_loss: 0.7194 - val_accuracy: 0.7440\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 202s 97ms/step - loss: 0.4840 - accuracy: 0.8363 - val_loss: 0.7940 - val_accuracy: 0.7343\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `BDLSTM_elu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 9s 59ms/step\n",
            "Test Accuracy: 0.730433\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"BDLSTM_relu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_8 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 50, 512)          559104    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_8 (Glo  (None, 512)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,482,645\n",
            "Trainable params: 1,482,645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `BDLSTM_relu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 214s 101ms/step - loss: 1.2049 - accuracy: 0.4952 - val_loss: 0.8314 - val_accuracy: 0.6992\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 203s 97ms/step - loss: 0.7063 - accuracy: 0.7490 - val_loss: 0.7373 - val_accuracy: 0.7302\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 199s 96ms/step - loss: 0.5061 - accuracy: 0.8285 - val_loss: 0.7619 - val_accuracy: 0.7286\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `BDLSTM_relu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 8s 59ms/step\n",
            "Test Accuracy: 0.734079\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Model: \"BDLSTM_leaky_relu\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_9 (Embedding)     (None, 50, 16)            890384    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 50, 512)          559104    \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " global_max_pooling1d_9 (Glo  (None, 512)              0         \n",
            " balMaxPooling1D)                                                \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 64)                32832     \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 5)                 325       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,482,645\n",
            "Trainable params: 1,482,645\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start training model `BDLSTM_leaky_relu`:\n",
            "_________________________________________________________________\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 207s 98ms/step - loss: 1.1387 - accuracy: 0.5292 - val_loss: 0.8043 - val_accuracy: 0.7073\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 211s 101ms/step - loss: 0.6746 - accuracy: 0.7609 - val_loss: 0.7235 - val_accuracy: 0.7348\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 211s 101ms/step - loss: 0.4890 - accuracy: 0.8328 - val_loss: 0.7615 - val_accuracy: 0.7381\n",
            "_________________________________________________________________\n",
            "\n",
            "\n",
            "\n",
            "Start testing model `BDLSTM_leaky_relu`:\n",
            "_________________________________________________________________\n",
            "129/129 [==============================] - 9s 62ms/step\n",
            "Test Accuracy: 0.743802\n",
            "**********************************************************************************************************************************\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for model_type in [\"GRU\", \"LSTM\", \"BDLSTM\"]:\n",
        "    for activation in [\"elu\", \"relu\", \"leaky_relu\"]:\n",
        "        model = MyNlp(model_type, activation)\n",
        "        model.train_test_pipeline(X_train, y_train, X_test, y_test, eval_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "yNZiyzXPglhL",
        "outputId": "3346d2de-a864-4961-923b-cab491931086"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>random</td>\n",
              "      <td>0.192929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>most_popular</td>\n",
              "      <td>0.279917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unique_words</td>\n",
              "      <td>0.301664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>multinomial_naive_bayes</td>\n",
              "      <td>0.444296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>random_forest_classifier</td>\n",
              "      <td>0.527153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GRU_elu</td>\n",
              "      <td>0.736266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GRU_elu</td>\n",
              "      <td>0.721682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GRU_relu</td>\n",
              "      <td>0.718036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GRU_leaky_relu</td>\n",
              "      <td>0.722654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LSTM_elu</td>\n",
              "      <td>0.721682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LSTM_relu</td>\n",
              "      <td>0.731891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LSTM_leaky_relu</td>\n",
              "      <td>0.716334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>BDLSTM_elu</td>\n",
              "      <td>0.730433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>BDLSTM_relu</td>\n",
              "      <td>0.734079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>BDLSTM_leaky_relu</td>\n",
              "      <td>0.743802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      method  accuracy\n",
              "0                     random  0.192929\n",
              "1               most_popular  0.279917\n",
              "2               unique_words  0.301664\n",
              "3    multinomial_naive_bayes  0.444296\n",
              "4   random_forest_classifier  0.527153\n",
              "5                    GRU_elu  0.736266\n",
              "6                    GRU_elu  0.721682\n",
              "7                   GRU_relu  0.718036\n",
              "8             GRU_leaky_relu  0.722654\n",
              "9                   LSTM_elu  0.721682\n",
              "10                 LSTM_relu  0.731891\n",
              "11           LSTM_leaky_relu  0.716334\n",
              "12                BDLSTM_elu  0.730433\n",
              "13               BDLSTM_relu  0.734079\n",
              "14         BDLSTM_leaky_relu  0.743802"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Результаты\n",
        "eval_df.to_csv(EVAL_CSV_NEW, index=False)\n",
        "eval_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "CVEouIuXZZeZ",
        "outputId": "eaa5aad9-f71a-4aa0-a618-aee20140b245"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>method</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BDLSTM_leaky_relu</td>\n",
              "      <td>0.743802</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>GRU_elu</td>\n",
              "      <td>0.736266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>BDLSTM_relu</td>\n",
              "      <td>0.734079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>LSTM_relu</td>\n",
              "      <td>0.731891</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>BDLSTM_elu</td>\n",
              "      <td>0.730433</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GRU_leaky_relu</td>\n",
              "      <td>0.722654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GRU_elu</td>\n",
              "      <td>0.721682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>LSTM_elu</td>\n",
              "      <td>0.721682</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GRU_relu</td>\n",
              "      <td>0.718036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LSTM_leaky_relu</td>\n",
              "      <td>0.716334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>random_forest_classifier</td>\n",
              "      <td>0.527153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>multinomial_naive_bayes</td>\n",
              "      <td>0.444296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>unique_words</td>\n",
              "      <td>0.301664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>most_popular</td>\n",
              "      <td>0.279917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>random</td>\n",
              "      <td>0.192929</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      method  accuracy\n",
              "0          BDLSTM_leaky_relu  0.743802\n",
              "1                    GRU_elu  0.736266\n",
              "2                BDLSTM_relu  0.734079\n",
              "3                  LSTM_relu  0.731891\n",
              "4                 BDLSTM_elu  0.730433\n",
              "5             GRU_leaky_relu  0.722654\n",
              "6                    GRU_elu  0.721682\n",
              "7                   LSTM_elu  0.721682\n",
              "8                   GRU_relu  0.718036\n",
              "9            LSTM_leaky_relu  0.716334\n",
              "10  random_forest_classifier  0.527153\n",
              "11   multinomial_naive_bayes  0.444296\n",
              "12              unique_words  0.301664\n",
              "13              most_popular  0.279917\n",
              "14                    random  0.192929"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Сортировка + рейтинг моделек:\n",
        "eval_df_sorted = eval_df.sort_values(by=\"accuracy\", ascending=False).reset_index(drop=True)\n",
        "eval_df_sorted.to_csv(EVAL_CSV_RATING, index=False)\n",
        "eval_df_sorted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gqsqe4ysCBDL"
      },
      "source": [
        "# Вывод\n",
        "\n",
        "Результаты моделей, на основе нейросетей показали примерно одинаковый результат (точность более 70%) что значительно лучше тех же моделей classic ML.\n",
        "При прогоне несколько раз - результаты могут отличаться, но в среднем все справляются нормально. (Разве что GRU и leaky_relu чаще других выбивались в лидеры)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "8e69818726fe5b763e541299fb74e99b21bc0aecd32c409206f20968507ef6ef"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
